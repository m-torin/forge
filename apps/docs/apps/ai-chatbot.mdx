---
title: "AI Chatbot"
description: "AI chatbot template built with Next.js and the AI SDK"
icon: "messages"
---

<div align="center">
  <a href="https://chat.vercel.ai/">
    <img
      alt="Next.js 14 and App Router-ready AI chatbot."
      src="https://chat.vercel.ai/opengraph-image.png"
    />
  </a>
  <h1>Chat SDK</h1>
</div>

<p align="center">
  Chat SDK is a free, open-source template built with Next.js and the AI SDK
  that helps you quickly build powerful chatbot applications.
</p>

<p align="center">
  <a href="https://chat-sdk.dev">
    <strong>Read Docs</strong>
  </a>{" "}
  ·
  <a href="#features">
    <strong>Features</strong>
  </a>{" "}
  ·
  <a href="#model-providers">
    <strong>Model Providers</strong>
  </a>{" "}
  ·
  <a href="#deploy-your-own">
    <strong>Deploy Your Own</strong>
  </a>{" "}
  ·
  <a href="#running-locally">
    <strong>Running locally</strong>
  </a>
</p>

<br />

# AI Chatbot

An open-source AI chatbot template built with Next.js and the AI SDK by Vercel.

## Features

- 🤖 **Multi-Provider AI Support** - Support for xAI (Grok), OpenAI, Anthropic,
  Google AI, and Perplexity
- 💬 **Real-time Chat** - Stream responses with resumable streams
- 🎨 **Artifacts** - Generate images, code, and documents
- 🔐 **Authentication** - GitHub and Google OAuth
- 📱 **Responsive Design** - Works on desktop and mobile
- 🌙 **Dark Mode** - Built-in dark mode support
- 🧪 **Testing** - Comprehensive test suite with Playwright

## Multi-Provider AI Support

This chatbot now supports multiple AI providers through a centralized model
configuration system, allowing users to choose from different models based on
their needs and available API keys.

### Supported Providers

1. **xAI (Grok)** - Primary provider with multimodal capabilities
2. **OpenAI** - GPT-4o and GPT-4o Mini models with reasoning support
3. **Anthropic** - Claude models including Opus 4 with advanced reasoning
4. **Google AI** - Gemini Pro and Gemini Flash models
5. **Perplexity** - Sonar models with web search capabilities

<Note>
  The available models are dynamically determined based on configured API keys
  and the centralized model registry in `@repo/ai/models`.
</Note>

### Environment Variables

Copy the following environment variables to your `.env.local` file:

```bash
# Database
POSTGRES_URL="postgresql://username:password@localhost:5432/ai_chatbot"
POSTGRES_PRISMA_URL="postgresql://username:password@localhost:5432/ai_chatbot?pgbouncer=true"
POSTGRES_URL_NON_POOLING="postgresql://username:password@localhost:5432/ai_chatbot"

# Auth (Better Auth)
BETTER_AUTH_SECRET="your-auth-secret-here"
AUTH_GITHUB_ID="your-github-client-id"
AUTH_GITHUB_SECRET="your-github-client-secret"
AUTH_GOOGLE_ID="your-google-client-id"
AUTH_GOOGLE_SECRET="your-google-client-secret"

# AI Providers (at least one required)
XAI_API_KEY="your-xai-api-key"               # xAI (Grok) - Primary
OPENAI_API_KEY="your-openai-api-key"         # OpenAI - Alternative
ANTHROPIC_API_KEY="your-anthropic-api-key"   # Anthropic - Alternative
GOOGLE_AI_API_KEY="your-google-ai-api-key"   # Google AI - Alternative
PERPLEXITY_API_KEY="your-perplexity-api-key" # Perplexity - Alternative

# Storage
BLOB_READ_WRITE_TOKEN="your-blob-read-write-token"

# Redis (for resumable streams) - Upstash Redis
REDIS_URL="redis://localhost:6379"
REDIS_TOKEN="your-redis-token"
UPSTASH_REDIS_REST_URL="your-upstash-redis-url"

# Vector Database (for RAG features)
UPSTASH_VECTOR_REST_URL="your-upstash-vector-url"
UPSTASH_VECTOR_REST_TOKEN="your-upstash-vector-token"
UPSTASH_VECTOR_NAMESPACE="your-namespace"

# Feature Flags (Optional)
FLAGS_SECRET="your-flags-secret"
POSTHOG_KEY="your-posthog-key"
POSTHOG_HOST="https://app.posthog.com"
EDGE_CONFIG="your-edge-config-url"

# Real Feature Implementation (Production Features)
ENABLE_REAL_IMAGE_GENERATION="false"
ENABLE_REAL_DOCUMENT_PROCESSING="false"
ENABLE_REAL_RAG_FEATURES="false"
ENABLE_REAL_CONTENT_CLASSIFICATION="false"
ENABLE_REAL_STREAMABLE_UI="false"

# MCP Configuration (JSON)
MCP_CONFIG='{"servers":{"context7":{"enabled":true}}}'

# Monitoring
SENTRY_DSN="your-sentry-dsn"

# Environment
NODE_ENV="development"

# Client Configuration
NEXT_PUBLIC_VERCEL_URL="http://localhost:3100"
NEXT_PUBLIC_APP_URL="http://localhost:3100"
NEXT_PUBLIC_PROTOTYPE_MODE="false"

# Client Feature Flags
NEXT_PUBLIC_MCP_CONFIG='{"servers":{"context7":{"enabled":true}}}'
NEXT_PUBLIC_POSTHOG_KEY="your-posthog-key"
NEXT_PUBLIC_POSTHOG_HOST="https://app.posthog.com"
NEXT_PUBLIC_VERCEL_ENV="development"
NEXT_PUBLIC_FORCE_DEMO_MODE="false"
```

### Provider Priority

The system uses the centralized model configuration to automatically select the
best available model based on:

1. **API Key Availability** - Only models with configured API keys are available
2. **Task Requirements** - Models are selected based on capabilities (chat,
   reasoning, vision)
3. **User Tier** - Free, Pro, or Enterprise users get access to different models
4. **Cost Optimization** - Balances performance with cost efficiency

```typescript
import { getBestModelForTask } from "@repo/ai/models";
import {
  hasAnthropicConfig,
  hasOpenAIConfig,
  hasGoogleAIConfig,
} from "@repo/ai/env";

// Automatic model selection
const chatModel = getBestModelForTask("chat");
if (hasAnthropicConfig() || hasOpenAIConfig() || hasGoogleAIConfig()) {
  // Provider API key available - use the model
}
```

### Model Selection

The chatbot uses the centralized model registry to dynamically populate
available models based on configured API keys and user permissions:

```typescript
import {
  getModelRecommendations,
  getModelsByCapability,
  canUserAccessModel,
} from "@repo/ai/models";

// Get available models for the user
const userTier = getUserTier(); // 'free' | 'pro' | 'enterprise'
const chatModels = getModelRecommendations("chat", userTier);
const reasoningModels = getModelsByCapability("reasoning").filter((modelId) =>
  canUserAccessModel(userTier, getModelConfig(modelId)?.costTier, false),
);
```

#### Model Categories:

- **Chat Models**: General conversation and assistance
- **Reasoning Models**: Advanced problem-solving with thinking process
- **Vision Models**: Image analysis and multimodal inputs
- **Search Models**: Real-time web search capabilities
- **Code Models**: Specialized for programming tasks

<Warning>
  Model availability is dynamic and depends on: - Configured API keys in
  environment variables - User subscription tier - Model deprecation status -
  Cost tier restrictions
</Warning>

## Getting Started

1. Clone the repository
2. Install dependencies: `pnpm install`
3. Set up your environment variables (see above)
4. Run the development server: `pnpm dev`
5. Open [http://localhost:3100](http://localhost:3100)

## Development

```bash
# Install dependencies
pnpm install

# Run development server
pnpm dev

# Run tests
pnpm test

# Run type checking
pnpm typecheck

# Run linting
pnpm lint
```

### Model Configuration

The AI chatbot uses the centralized model configuration from `@repo/ai`. To add
or update models:

1. Update model metadata in `packages/ai/src/shared/models/metadata.ts`
2. Models are automatically available in the chatbot
3. The UI dynamically updates based on available models

```typescript
// Example: Using centralized model selection
import { selectModel } from "@repo/ai/models";
import { registry } from "@repo/ai/server";

const model = selectModel({
  strategy: "balanced",
  userTier: currentUser.tier,
  fallbackEnabled: true,
});

const aiModel = registry.languageModel(`${provider}:${model}`);
```

## Deployment

The easiest way to deploy your AI chatbot is to use the
[Vercel Platform](https://vercel.com/new/clone?repository-url=https://github.com/vercel/ai-chatbot).

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/vercel/ai-chatbot&env=AUTH_SECRET&envDescription=Learn
more about how to get the API Keys for the
application&envLink=https://github.com/vercel/ai-chatbot/blob/main/.env.example&demo-title=AI
Chatbot&demo-description=An Open-Source AI Chatbot Template Built With Next.js
and the AI SDK by Vercel.&demo-url=https://chat.vercel.ai)

## License

MIT License - see the
[LICENSE](https://github.com/vercel/ai-chatbot/blob/main/LICENSE) file for
details.
